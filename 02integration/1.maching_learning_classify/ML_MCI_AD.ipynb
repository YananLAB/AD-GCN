{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2a10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ec3d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''读取数据'''\n",
    "data_path = './concatData.xlsx'\n",
    "MCI_AD_Data = pd.read_excel(data_path,sheet_name=\"MCI_AD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4575b53c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 345, 1: 35})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(MCI_AD_Data['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20335bf",
   "metadata": {},
   "source": [
    "### 1、串联拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307618ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# 忽略所有的 ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# 定义模型\n",
    "models = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=20),\n",
    "    'Ridge': LogisticRegression(penalty='l2', solver='liblinear'),\n",
    "    'BernoulliNB': BernoulliNB(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'GDBT': GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "# 定义评分标准\n",
    "scoring = {\n",
    "    'MCC': make_scorer(matthews_corrcoef),\n",
    "    'Accuracy': make_scorer(accuracy_score),\n",
    "    'Precision': make_scorer(precision_score),\n",
    "    'Recall': make_scorer(recall_score),\n",
    "    'F1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# 交叉验证\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True,random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "cf50f7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_and_remove_danger_samples(X, y, k=5): \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    majority_class = max(set(y), key=list(y).count)\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    neigh.fit(X)\n",
    "    danger_indices = []\n",
    "    for idx, x in enumerate(X):\n",
    "        if y[idx] == majority_class:\n",
    "            neighbors = neigh.kneighbors([x], return_distance=False)\n",
    "            neighbor_labels = y[neighbors[0]]\n",
    "            minority_count = np.sum(neighbor_labels != majority_class)\n",
    "            if minority_count > k / 2:\n",
    "                danger_indices.append(idx)\n",
    "    X_cleaned = np.delete(X, danger_indices, axis=0)\n",
    "    y_cleaned = np.delete(y, danger_indices, axis=0)\n",
    "    \n",
    "    return X_cleaned, y_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee17b93",
   "metadata": {},
   "source": [
    "#### （0）临床数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "6d37b4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 345, 1: 35})\n",
      "过采样 dataset shape Counter({0: 345, 1: 175})\n",
      "欠采样 dataset shape: Counter({0: 306, 1: 175})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# 标准化数据\n",
    "clinic_X = MCI_AD_Data[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT']]\n",
    "clinic_y = MCI_AD_Data['status']\n",
    "print('Original dataset shape %s' % Counter(clinic_y))\n",
    "\n",
    "\n",
    "'''过采样'''\n",
    "sm0 = BorderlineSMOTE(\n",
    "    random_state=42,\n",
    "    kind=\"borderline-1\",\n",
    "    sampling_strategy={0: 345, 1: 175 },#179 20  IR=6.92\n",
    "    k_neighbors=5, #确定邻居点的数量\n",
    "    m_neighbors=10) #指定在合成样本生成过程中从近邻点中选择多少个样本作为参考\n",
    "X_bdsmote0, y_bdsmote0 = sm0.fit_resample(clinic_X, clinic_y)\n",
    "print('过采样 dataset shape %s' % Counter(y_bdsmote0))\n",
    "# 合并为一个新的dataframe\n",
    "y_bdsmote0 = pd.Series(y_bdsmote0,name=\"status\")\n",
    "data_bdsmote0 = pd.concat([X_bdsmote0, y_bdsmote0], axis=1)\n",
    "\n",
    "\n",
    "'''欠采样'''\n",
    "X_cleaned0, y_cleaned0 = find_and_remove_danger_samples(X_bdsmote0.values, data_bdsmote0[\"status\"], k=100)\n",
    "print(f\"欠采样 dataset shape: {Counter(y_cleaned0)}\")\n",
    "# 合并为一个新的dataframe\n",
    "X_bdknn0 = pd.DataFrame(X_cleaned0,columns=X_bdsmote0.columns)\n",
    "y_bdknn0 = pd.Series(y_cleaned0,name=\"status\")\n",
    "data_bdknn0 = pd.concat([X_bdknn0, y_bdknn0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "16339396",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_ret = {}\n",
    "\n",
    "# 标准化\n",
    "standard_scaler0 = StandardScaler()\n",
    "standard_scaler0.fit(X_bdknn0)\n",
    "X_bdknn0 = standard_scaler0.transform(X_bdknn0)\n",
    "X1 = pd.DataFrame(X_bdknn0,columns=[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT']])\n",
    "\n",
    "\n",
    "for name, model in models.items():    \n",
    "    scores = cross_validate(model , X1, y_bdknn0, cv=cv, scoring=scoring)\n",
    "    clinic_ret[name] = {\n",
    "        'MCC': np.mean(scores['test_MCC']),\n",
    "        'Accuracy': np.mean(scores['test_Accuracy']),\n",
    "        'Precision': np.mean(scores['test_Precision']),\n",
    "        'Recall': np.mean(scores['test_Recall']),\n",
    "        'F1': np.mean(scores['test_F1'])\n",
    "    }\n",
    "\n",
    "# 输出结果\n",
    "df_clinic = pd.DataFrame(clinic_ret).T\n",
    "# print(df_clinic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ad76d5",
   "metadata": {},
   "source": [
    "#### （1）临床数据+PRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "8b875567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 345, 1: 35})\n",
      "过采样 dataset shape Counter({0: 345, 1: 145})\n",
      "欠采样 dataset shape: Counter({0: 334, 1: 145})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# 标准化数据\n",
    "prs_X = MCI_AD_Data[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT', \n",
    "                  'cov_prs']]\n",
    "prs_y = MCI_AD_Data['status']\n",
    "print('Original dataset shape %s' % Counter(prs_y))\n",
    "\n",
    "\n",
    "'''过采样'''\n",
    "sm1 = BorderlineSMOTE(\n",
    "    random_state=42,\n",
    "    kind=\"borderline-1\",\n",
    "    sampling_strategy={0: 345, 1: 145},\n",
    "    k_neighbors=5, #确定邻居点的数量\n",
    "    m_neighbors=10) #指定在合成样本生成过程中从近邻点中选择多少个样本作为参考\n",
    "X_bdsmote1, y_bdsmote1 = sm1.fit_resample(prs_X, y)\n",
    "print('过采样 dataset shape %s' % Counter(y_bdsmote1))\n",
    "# 合并为一个新的dataframe\n",
    "y_bdsmote1 = pd.Series(y_bdsmote1,name=\"status\")\n",
    "data_bdsmote1 = pd.concat([X_bdsmote1, y_bdsmote1], axis=1)\n",
    "\n",
    "\n",
    "'''欠采样'''\n",
    "X_cleaned1, y_cleaned1 = find_and_remove_danger_samples(X_bdsmote1.values, data_bdsmote1[\"status\"], k=100)\n",
    "print(f\"欠采样 dataset shape: {Counter(y_cleaned1)}\")\n",
    "# 合并为一个新的dataframe\n",
    "X_bdknn1 = pd.DataFrame(X_cleaned1,columns=X_bdsmote1.columns)\n",
    "y_bdknn1 = pd.Series(y_cleaned1,name=\"status\")\n",
    "data_bdknn1 = pd.concat([X_bdknn1, y_bdknn1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "4951e04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_prs_ret = {}\n",
    "\n",
    "# # 标准化\n",
    "standard_scaler1 = StandardScaler()\n",
    "standard_scaler1.fit(X_bdknn1)\n",
    "X_bdknn1 = standard_scaler1.transform(X_bdknn1)\n",
    "X2 = pd.DataFrame(X_bdknn1,columns=[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT', \n",
    "                  'cov_prs']])\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_validate(model, X2, y_bdknn1, cv=cv, scoring=scoring)\n",
    "    clinic_prs_ret[name] = {\n",
    "        'MCC': np.mean(scores['test_MCC']),\n",
    "        'Accuracy': np.mean(scores['test_Accuracy']),\n",
    "        'Precision': np.mean(scores['test_Precision']),\n",
    "        'Recall': np.mean(scores['test_Recall']),\n",
    "        'F1': np.mean(scores['test_F1'])\n",
    "    }\n",
    "\n",
    "# 输出结果\n",
    "df_clinic_prs = pd.DataFrame(clinic_prs_ret).T\n",
    "# print(df_clinic_prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cf1554",
   "metadata": {},
   "source": [
    "#### （2）临床数据+PRS+甲基化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "34c409b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "过采样 dataset shape Counter({0: 345, 1: 125})\n",
      "欠采样 dataset shape: Counter({0: 344, 1: 125})\n"
     ]
    }
   ],
   "source": [
    "cg_X = MCI_AD_Data[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT', \n",
    "                  'cov_prs',\n",
    "                  'cg14718065','cg09440270', 'cg06980531', 'cg04143909', 'cg08026735', 'cg16664778',\n",
    "                  'cg05313129', 'cg02168442', 'cg22832802', 'cg15802263']]\n",
    "cg_y = MCI_AD_Data['status']\n",
    "\n",
    "'''过采样'''\n",
    "sm2 = BorderlineSMOTE(\n",
    "    random_state=42,\n",
    "    kind=\"borderline-1\",\n",
    "    sampling_strategy={0: 345, 1: 125},\n",
    "    k_neighbors=5, #确定邻居点的数量\n",
    "    m_neighbors=10) #指定在合成样本生成过程中从近邻点中选择多少个样本作为参考\n",
    "X_bdsmote2, y_bdsmote2 = sm2.fit_resample(cg_X, cg_y)\n",
    "print('过采样 dataset shape %s' % Counter(y_bdsmote2))\n",
    "# 合并为一个新的dataframe\n",
    "y_bdsmote2 = pd.Series(y_bdsmote2,name=\"status\")\n",
    "data_bdsmote2 = pd.concat([X_bdsmote2, y_bdsmote2], axis=1)\n",
    "\n",
    "\n",
    "'''欠采样'''\n",
    "X_cleaned2, y_cleaned2 = find_and_remove_danger_samples(X_bdsmote2.values, data_bdsmote2[\"status\"], k=100)\n",
    "print(f\"欠采样 dataset shape: {Counter(y_cleaned2)}\")\n",
    "# 合并为一个新的dataframe\n",
    "X_bdknn2 = pd.DataFrame(X_cleaned2,columns=X_bdsmote2.columns)\n",
    "y_bdknn2 = pd.Series(y_cleaned2,name=\"status\")\n",
    "data_bdknn2 = pd.concat([X_bdknn2, y_bdknn2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a4ae42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clinic_prs_methy_ret = {}\n",
    "\n",
    "# # 标准化\n",
    "standard_scaler2 = StandardScaler()\n",
    "standard_scaler2.fit(X_bdknn2)\n",
    "X_bdknn2 = standard_scaler2.transform(X_bdknn2)\n",
    "X3 = pd.DataFrame(X_bdknn2,columns=['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT', \n",
    "                  'cov_prs',\n",
    "                  'cg14718065','cg09440270', 'cg06980531', 'cg04143909', 'cg08026735', 'cg16664778',\n",
    "                  'cg05313129', 'cg02168442', 'cg22832802', 'cg15802263'])\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_validate(model, X3, y_bdknn2, cv=cv, scoring=scoring)\n",
    "    clinic_prs_methy_ret[name] = {\n",
    "        'MCC': np.mean(scores['test_MCC']),\n",
    "        'Accuracy': np.mean(scores['test_Accuracy']),\n",
    "        'Precision': np.mean(scores['test_Precision']),\n",
    "        'Recall': np.mean(scores['test_Recall']),\n",
    "        'F1': np.mean(scores['test_F1'])\n",
    "    }\n",
    "\n",
    "# 输出结果\n",
    "df_clinic_prs_methy = pd.DataFrame(clinic_prs_methy_ret).T\n",
    "# print(df_clinic_prs_methy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b8f7f",
   "metadata": {},
   "source": [
    "#### （3）打印结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "34ff4e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  MCC  Accuracy  Precision    Recall        F1\n",
      "KNN          0.383912  0.715163   0.608044  0.605714  0.605825\n",
      "Ridge        0.305888  0.694480   0.609848  0.440000  0.508447\n",
      "BernoulliNB  0.207835  0.659042   0.536470  0.354286  0.418117\n",
      "SVM          0.455028  0.746306   0.647836  0.662857  0.654560\n",
      "RF           0.573487  0.798325   0.724343  0.742857  0.729601\n",
      "AdaBoost     0.511414  0.773303   0.691134  0.685714  0.684989\n",
      "XGBoost      0.486549  0.762930   0.679720  0.662857  0.669766\n",
      "GDBT         0.483332  0.762865   0.690445  0.640000  0.660397\n",
      "                  MCC  Accuracy  Precision    Recall        F1\n",
      "KNN          0.449744  0.761952   0.610606  0.634483  0.616498\n",
      "Ridge        0.310773  0.730636   0.612460  0.372414  0.456256\n",
      "BernoulliNB  0.413335  0.753531   0.598753  0.579310  0.584546\n",
      "SVM          0.466752  0.782741   0.699598  0.537931  0.593031\n",
      "RF           0.628751  0.839167   0.751852  0.737931  0.736699\n",
      "AdaBoost     0.531575  0.805855   0.708726  0.627586  0.660976\n",
      "XGBoost      0.629739  0.843311   0.765989  0.717241  0.736897\n",
      "GDBT         0.584505  0.824561   0.743075  0.675862  0.701790\n",
      "                  MCC  Accuracy  Precision  Recall        F1\n",
      "KNN          0.464170  0.778334   0.574663   0.664  0.614512\n",
      "Ridge        0.354969  0.763235   0.564907   0.456  0.503084\n",
      "BernoulliNB  0.490585  0.801624   0.626805   0.624  0.623443\n",
      "SVM          0.612196  0.852848   0.749643   0.672  0.706566\n",
      "RF           0.687998  0.882681   0.853196   0.680  0.753944\n",
      "AdaBoost     0.593103  0.842256   0.712302   0.688  0.696049\n",
      "XGBoost      0.661841  0.865683   0.748291   0.760  0.750030\n",
      "GDBT         0.652422  0.865660   0.774685   0.712  0.737866\n"
     ]
    }
   ],
   "source": [
    "print(df_clinic)\n",
    "print(df_clinic_prs)\n",
    "print(df_clinic_prs_methy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842460b",
   "metadata": {},
   "source": [
    "### 2、转化拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "862cfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PCA降维'''\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "models_trans = {\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Ridge': LogisticRegression(penalty='l2', solver='liblinear'),\n",
    "    'Bayes': BernoulliNB(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'RF': RandomForestClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'GDBT': GradientBoostingClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabb1ccb",
   "metadata": {},
   "source": [
    "#### （0）clinic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "88bfa272",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_clinic_ret = {}\n",
    "\n",
    "ft0_X = X1[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT']]\n",
    "ft0_y = data_bdknn0['status']\n",
    "\n",
    "pca0 = PCA(n_components=3)   \n",
    "pca0_X = pca0.fit_transform(ft0_X)\n",
    "\n",
    "for name, model in models_trans.items():\n",
    "    scores = cross_validate(model, pca0_X, ft0_y, cv=cv, scoring=scoring)\n",
    "    trans_clinic_ret[name] = {\n",
    "        'MCC': np.mean(scores['test_MCC']),\n",
    "        'Accuracy': np.mean(scores['test_Accuracy']),\n",
    "        'Precision': np.mean(scores['test_Precision']),\n",
    "        'Recall': np.mean(scores['test_Recall']),\n",
    "        'F1': np.mean(scores['test_F1'])\n",
    "    }\n",
    "\n",
    "# 输出结果\n",
    "df_trans_clinic = pd.DataFrame(trans_clinic_ret).T\n",
    "# print(df_trans_clinic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3d306",
   "metadata": {},
   "source": [
    "#### （1）clinic+prs_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "60717d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_clinic_prs_ret = {}\n",
    "\n",
    "ft1_X = X2[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT','cov_prs']]\n",
    "ft1_y = data_bdknn1['status']\n",
    "\n",
    "pca1 = PCA(n_components=4)\n",
    "pca1_X = pca1.fit_transform(ft1_X)\n",
    "pca1_X = pd.DataFrame(pca1_X)\n",
    "\n",
    "for name, model in models_trans.items():\n",
    "    scores = cross_validate(model, pca1_X, ft1_y, cv=cv, scoring=scoring)\n",
    "    trans_clinic_prs_ret[name] = {\n",
    "        'MCC': np.mean(scores['test_MCC']),\n",
    "        'Accuracy': np.mean(scores['test_Accuracy']),\n",
    "        'Precision': np.mean(scores['test_Precision']),\n",
    "        'Recall': np.mean(scores['test_Recall']),\n",
    "        'F1': np.mean(scores['test_F1'])\n",
    "    }\n",
    "\n",
    "# 输出结果\n",
    "df_trans_clinic_prs = pd.DataFrame(trans_clinic_prs_ret).T\n",
    "# print(df_trans_clinic_prs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bd75a",
   "metadata": {},
   "source": [
    "#### （2）clinic+prs+methy_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "b0ef04c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_clinic_prs_methy_ret = {}\n",
    "\n",
    "ft21_X = X3[['PTGENDER', 'PTMARRY', 'AGE','PTEDUCAT','cov_prs']]\n",
    "ft22_X = X3[['cg14718065','cg09440270', 'cg06980531', 'cg04143909', 'cg08026735', \n",
    "             'cg16664778','cg05313129', 'cg02168442', 'cg22832802', 'cg15802263']]\n",
    "ft2_y = data_bdknn2['status']\n",
    "\n",
    "pca21_X = pca1.fit_transform(ft21_X)\n",
    "pca21_X = pd.DataFrame(pca21_X,columns=[f'PCA1_{i+1}' for i in range(pca21_X.shape[1])])\n",
    "\n",
    "pca2 = PCA(n_components=5)  \n",
    "pca22_X = pca2.fit_transform(ft22_X)\n",
    "pca22_X = pd.DataFrame(pca22_X,columns=[f'PCA2_{i+1}' for i in range(pca22_X.shape[1])])\n",
    "\n",
    "combined_pca2 =pd.concat([pca21_X, pca22_X],axis=1)\n",
    "\n",
    "for name, model in models_trans.items():\n",
    "    scores = cross_validate(model, combined_pca2, ft2_y, cv=cv, scoring=scoring)\n",
    "    trans_clinic_prs_methy_ret[name] = {\n",
    "        'MCC': np.mean(scores['test_MCC']),\n",
    "        'Accuracy': np.mean(scores['test_Accuracy']),\n",
    "        'Precision': np.mean(scores['test_Precision']),\n",
    "        'Recall': np.mean(scores['test_Recall']),\n",
    "        'F1': np.mean(scores['test_F1'])\n",
    "    }\n",
    "\n",
    "# 输出结果\n",
    "df_trans_clinic_prs_methy = pd.DataFrame(trans_clinic_prs_methy_ret).T\n",
    "# print(df_trans_clinic_prs_methy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ec1764",
   "metadata": {},
   "source": [
    "#### （3）打印结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "1f44470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               MCC  Accuracy  Precision    Recall        F1\n",
      "KNN       0.425764  0.739991   0.656263  0.588571  0.617955\n",
      "Ridge     0.281709  0.686147   0.614907  0.388571  0.474109\n",
      "Bayes     0.307734  0.690163   0.594358  0.480000  0.527917\n",
      "SVM       0.395513  0.725515   0.637691  0.571429  0.602101\n",
      "RF        0.511353  0.773389   0.698031  0.680000  0.687600\n",
      "AdaBoost  0.470701  0.758849   0.686777  0.622857  0.651932\n",
      "XGBoost   0.488106  0.762887   0.679599  0.668571  0.673075\n",
      "GDBT      0.480935  0.760825   0.682640  0.651429  0.665733\n",
      "               MCC  Accuracy  Precision    Recall        F1\n",
      "KNN       0.476797  0.772346   0.637340  0.648276  0.637767\n",
      "Ridge     0.333290  0.738969   0.650389  0.372414  0.463582\n",
      "Bayes     0.319191  0.732719   0.584769  0.413793  0.479791\n",
      "SVM       0.455223  0.776535   0.698701  0.524138  0.585949\n",
      "RF        0.561884  0.814079   0.720567  0.668966  0.688133\n",
      "AdaBoost  0.428106  0.761886   0.620648  0.572414  0.590979\n",
      "XGBoost   0.530369  0.797346   0.699048  0.655172  0.669981\n",
      "GDBT      0.500478  0.791140   0.676600  0.620690  0.644945\n",
      "               MCC  Accuracy  Precision  Recall        F1\n",
      "KNN       0.568056  0.831503   0.693188   0.672  0.680199\n",
      "Ridge     0.433350  0.793068   0.659359   0.480  0.551869\n",
      "Bayes     0.425374  0.788881   0.650175   0.480  0.545892\n",
      "SVM       0.573124  0.842096   0.747387   0.608  0.666466\n",
      "RF        0.628878  0.859208   0.798881   0.648  0.710770\n",
      "AdaBoost  0.393331  0.771951   0.586799   0.504  0.539779\n",
      "XGBoost   0.578021  0.840059   0.730643   0.640  0.678184\n",
      "GDBT      0.502398  0.814436   0.699890   0.552  0.612808\n"
     ]
    }
   ],
   "source": [
    "print(df_trans_clinic)\n",
    "print(df_trans_clinic_prs)\n",
    "print(df_trans_clinic_prs_methy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20795ef7",
   "metadata": {},
   "source": [
    "### 3、模型拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "890c6474",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''集成学习：投票分类'''\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import log_loss, confusion_matrix, roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# 定义基学习器 DecisionTreeClassifier\n",
    "classifiers = {\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'LR':  LogisticRegression(),\n",
    "    'NaiveBayes': BernoulliNB(),#BernoulliNB  GaussianNB\n",
    "    'SVM': SVC(probability=True),\n",
    "    'RF': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "def find_bestModel(X,Y):\n",
    "    '''寻找最佳模型'''\n",
    "    best_model = None\n",
    "    best_score = -np.inf  # 负对数损失的最小值是负无穷大\n",
    "    best_model_name = ''\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        # 使用五折交叉验证\n",
    "        kf = StratifiedKFold(n_splits=5)\n",
    "        fold_scores = []\n",
    "        for train_index, test_index in kf.split(X,Y):\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = Y[train_index], Y[test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred_proba = clf.predict_proba(X_test)\n",
    "            fold_scores.append(-log_loss(y_test, y_pred_proba))  # 负对数损失\n",
    "        \n",
    "        mean_score = np.mean(fold_scores)\n",
    "\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_model = clf\n",
    "            best_model_name = name\n",
    "\n",
    "    return best_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "d00833c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ft1 model: SVC(probability=True)\n",
      "ft1 model: SVC(probability=True)\n",
      "ft2 model: SVC(probability=True)\n",
      "ft2 model: RandomForestClassifier()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找到最佳子模型\n",
    "ft0_model_name = find_bestModel(ft0_X,ft0_y)\n",
    "ft0_model = classifiers[ft0_model_name]\n",
    "print(\"ft1 model:\",ft0_model)\n",
    "ft1_model_name = find_bestModel(ft1_X,ft1_y)\n",
    "ft1_model = classifiers[ft1_model_name]\n",
    "print(\"ft1 model:\",ft1_model)\n",
    "\n",
    "\n",
    "ft21_model_name = find_bestModel(ft21_X,ft2_y)\n",
    "ft21_model = classifiers[ft21_model_name]\n",
    "print(\"ft2 model:\",ft21_model)\n",
    "ft22_model_name = find_bestModel(ft22_X,ft2_y)\n",
    "ft22_model = classifiers[ft22_model_name]\n",
    "print(\"ft2 model:\",ft22_model)\n",
    "\n",
    "# 训练模型\n",
    "ft0_model.fit(ft0_X, ft0_y)\n",
    "ft1_model.fit(ft1_X, ft1_y)\n",
    "\n",
    "ft21_model.fit(ft21_X, ft2_y)\n",
    "ft22_model.fit(ft22_X, ft2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "3980d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Confusion Matrix:\n",
      "[[50 12]\n",
      " [10 25]]\n",
      "----------------------------------------\n",
      "Fold 2 Confusion Matrix:\n",
      "[[51 10]\n",
      " [13 22]]\n",
      "----------------------------------------\n",
      "Fold 3 Confusion Matrix:\n",
      "[[46 15]\n",
      " [ 9 26]]\n",
      "----------------------------------------\n",
      "Fold 4 Confusion Matrix:\n",
      "[[53  8]\n",
      " [10 25]]\n",
      "----------------------------------------\n",
      "Fold 5 Confusion Matrix:\n",
      "[[47 14]\n",
      " [14 21]]\n",
      "----------------------------------------\n",
      "Average MCC: 0.4868\n",
      "Average Accuracy: 0.7609\n",
      "Average Precision: 0.6710\n",
      "Average Recall: 0.6800\n",
      "Average F1 Score: 0.6741\n"
     ]
    }
   ],
   "source": [
    "'''第一：仅计算 ft0 最佳子模型'''\n",
    "\n",
    "# 创建五折交叉验证器\n",
    "ft0_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化用于保存各折结果的列表\n",
    "ft0_confusion_matrices = []\n",
    "ft0_mccs = []\n",
    "ft0_accuracies = []\n",
    "ft0_precisions = []\n",
    "ft0_recalls = []\n",
    "ft0_f1_scores = []\n",
    "\n",
    "\n",
    "# 执行五折交叉验证\n",
    "for fold, (train_index, test_index) in enumerate(ft0_skf.split(ft0_X, ft0_y)):\n",
    "    # 分割数据集\n",
    "    X_train, X_test = ft0_X.iloc[train_index], ft0_X.iloc[test_index]\n",
    "    y_train, y_test = ft0_y[train_index], ft0_y[test_index]\n",
    "\n",
    "    # 训练模型\n",
    "    ft0_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测结果\n",
    "    y_pred = ft0_model.predict(X_test)\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ft0_confusion_matrices.append(cm)\n",
    "    \n",
    "    # 计算各项指标\n",
    "    ft0_mccs.append(matthews_corrcoef(y_test, y_pred))\n",
    "    ft0_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    ft0_precisions.append(precision_score(y_test, y_pred))\n",
    "    ft0_recalls.append(recall_score(y_test, y_pred))\n",
    "    ft0_f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    # 输出当前折的混淆矩阵\n",
    "    print(f\"Fold {fold + 1} Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    \n",
    "# 计算并输出所有折的平均值\n",
    "print(f\"Average MCC: {np.mean(ft0_mccs):.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(ft0_accuracies):.4f}\")\n",
    "print(f\"Average Precision: {np.mean(ft0_precisions):.4f}\")\n",
    "print(f\"Average Recall: {np.mean(ft0_recalls):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(ft0_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "98bbef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Confusion Matrix:\n",
      "[[53 14]\n",
      " [12 17]]\n",
      "----------------------------------------\n",
      "Fold 2 Confusion Matrix:\n",
      "[[62  5]\n",
      " [14 15]]\n",
      "----------------------------------------\n",
      "Fold 3 Confusion Matrix:\n",
      "[[64  3]\n",
      " [11 18]]\n",
      "----------------------------------------\n",
      "Fold 4 Confusion Matrix:\n",
      "[[63  4]\n",
      " [14 15]]\n",
      "----------------------------------------\n",
      "Fold 5 Confusion Matrix:\n",
      "[[56 10]\n",
      " [11 18]]\n",
      "----------------------------------------\n",
      "Average MCC: 0.5023\n",
      "Average Accuracy: 0.7954\n",
      "Average Precision: 0.7176\n",
      "Average Recall: 0.5724\n",
      "Average F1 Score: 0.6311\n"
     ]
    }
   ],
   "source": [
    "'''第二：仅计算 ft1 最佳子模型'''\n",
    "\n",
    "# 创建五折交叉验证器\n",
    "ft1_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# 初始化用于保存各折结果的列表\n",
    "ft1_confusion_matrices = []\n",
    "ft1_mccs = []\n",
    "ft1_accuracies = []\n",
    "ft1_precisions = []\n",
    "ft1_recalls = []\n",
    "ft1_f1_scores = []\n",
    "\n",
    "\n",
    "# 执行五折交叉验证\n",
    "for fold, (train_index, test_index) in enumerate(ft1_skf.split(ft1_X, ft1_y)):\n",
    "    # 分割数据集\n",
    "    X_train, X_test = ft1_X.iloc[train_index], ft1_X.iloc[test_index]\n",
    "    y_train, y_test = ft1_y[train_index], ft1_y[test_index]\n",
    "\n",
    "    # 训练模型\n",
    "    ft1_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 预测结果\n",
    "    y_pred = ft1_model.predict(X_test)\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    ft1_confusion_matrices.append(cm)\n",
    "    \n",
    "    # 计算各项指标\n",
    "    ft1_mccs.append(matthews_corrcoef(y_test, y_pred))\n",
    "    ft1_accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    ft1_precisions.append(precision_score(y_test, y_pred))\n",
    "    ft1_recalls.append(recall_score(y_test, y_pred))\n",
    "    ft1_f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    # 输出当前折的混淆矩阵\n",
    "    print(f\"Fold {fold + 1} Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    \n",
    "# 计算并输出所有折的平均值\n",
    "print(f\"Average MCC: {np.mean(ft1_mccs):.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(ft1_accuracies):.4f}\")\n",
    "print(f\"Average Precision: {np.mean(ft1_precisions):.4f}\")\n",
    "print(f\"Average Recall: {np.mean(ft1_recalls):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(ft1_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b095e364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Confusion Matrix:\n",
      "[[63  6]\n",
      " [ 6 19]]\n",
      "----------------------------------------\n",
      "Fold 2 Confusion Matrix:\n",
      "[[66  3]\n",
      " [ 9 16]]\n",
      "----------------------------------------\n",
      "Fold 3 Confusion Matrix:\n",
      "[[66  3]\n",
      " [ 7 18]]\n",
      "----------------------------------------\n",
      "Fold 4 Confusion Matrix:\n",
      "[[65  4]\n",
      " [ 9 16]]\n",
      "----------------------------------------\n",
      "Fold 5 Confusion Matrix:\n",
      "[[64  4]\n",
      " [ 4 21]]\n",
      "----------------------------------------\n",
      "Average MCC: 0.6913\n",
      "Average Accuracy: 0.8828\n",
      "Average Precision: 0.8828\n",
      "Average Recall: 0.7200\n",
      "Average F1 Score: 0.7642\n"
     ]
    }
   ],
   "source": [
    "'''第三：集成两个子模型'''\n",
    "# 创建集成模型（软投票）\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('model_1', ft21_model),\n",
    "    ('model_2', ft22_model)\n",
    "], voting='soft')\n",
    "\n",
    "# 进行五折交叉验证并输出每一折的混淆矩阵\n",
    "vt_skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "\n",
    "# 存储各折的评价指标\n",
    "vt_mcc_scores = []\n",
    "vt_accuracy_scores = []\n",
    "vt_precision_scores = []\n",
    "vt_recall_scores = []\n",
    "vt_f1_scores = []\n",
    "vt_confusion_matrix = []\n",
    "\n",
    "for train_index, test_index in vt_skf.split(np.hstack((ft21_X, ft22_X)),ft2_y):\n",
    "    X_train, X_test = np.hstack((ft21_X, ft22_X))[train_index], np.hstack((ft21_X, ft22_X))[test_index]\n",
    "    y_train, y_test = ft2_y[train_index], ft2_y[test_index]\n",
    "    \n",
    "    # 训练和预测\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    y_pred = ensemble_model.predict(X_test)\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    # 输出当前折的混淆矩阵\n",
    "    print(f\"Fold {fold} Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # 计算并存储评价指标\n",
    "    vt_confusion_matrix.append(cm)\n",
    "    vt_mcc_scores.append(matthews_corrcoef(y_test, y_pred))\n",
    "    vt_accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    vt_precision_scores.append(precision_score(y_test, y_pred))\n",
    "    vt_recall_scores.append(recall_score(y_test, y_pred))\n",
    "    vt_f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "\n",
    "# 计算并输出所有折的平均值\n",
    "print(f\"Average MCC: {np.mean(vt_mcc_scores):.4f}\")\n",
    "print(f\"Average Accuracy: {np.mean(vt_accuracy_scores):.4f}\")\n",
    "print(f\"Average Precision: {np.mean(vt_accuracy_scores):.4f}\")\n",
    "print(f\"Average Recall: {np.mean(vt_recall_scores):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(vt_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a28d3743",
   "metadata": {},
   "source": [
    "# 1 :175  145 125\n",
    "# C\n",
    "Average MCC: 0.4868\n",
    "Average Accuracy: 0.7609\n",
    "Average Precision: 0.6710\n",
    "Average Recall: 0.6800\n",
    "Average F1 Score: 0.6741\n",
    "\n",
    "# C+P\n",
    "\n",
    "Average MCC: 0.5023\n",
    "Average Accuracy: 0.7954\n",
    "Average Precision: 0.7176\n",
    "Average Recall: 0.5724\n",
    "Average F1 Score: 0.6311\n",
    "\n",
    "# C+P+M\n",
    "Average MCC: 0.6913\n",
    "Average Accuracy: 0.8828\n",
    "Average Precision: 0.8828\n",
    "Average Recall: 0.7200\n",
    "Average F1 Score: 0.7642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cf915",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
